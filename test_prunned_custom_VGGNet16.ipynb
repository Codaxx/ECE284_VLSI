{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee5fd321-50c1-4323-b8b7-8417f8e8f4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models.quant_layer import *\n",
    "from models.VGG16_custom import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d7a496b-352d-444c-b24d-3c7dfd3ca81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'NVIDIA GeForce GTX 1080 Ti')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_gpu else \"cpu\") \n",
    "use_gpu, torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d710bef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "model_name = \"VGG16_custom1\"\n",
    "model = VGG16_custom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1754bbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdir = 'result/'+str(model_name)+'/model_best.pth.tar'\n",
    "checkpoint = torch.load(fdir)\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "754bf6a4-12c3-4d37-a631-8986feeb869a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# means and stds for individual RGB channels\n",
    "# image = (image - mean) / std\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2180c004-6a73-4023-8cfe-cd36c9051170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    }
   ],
   "source": [
    "print_freq = len(testloader) / 4\n",
    "print(print_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2785d28-7249-48f8-b8c2-daa485ef6d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "            \n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36fa6d1c-11f0-4d68-a1df-e4fe8b9ee2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True) # topk(k, dim=None, largest=True, sorted=True)\n",
    "                                               # will output (max value, its index)\n",
    "    pred = pred.t()           # transpose\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))   # \"-1\": calculate automatically\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)  # view(-1): make a flattened 1D tensor\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))   # correct: size of [maxk, batch_size]\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2059eeee-e13b-4c3c-aed7-247612576958",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n    ## n is impact factor\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29f8a0d6-54cd-43fa-b760-3903f8536a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG_quant(\n",
       "  (features): Sequential(\n",
       "    (0): QuantConv2d(\n",
       "      3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): QuantConv2d(\n",
       "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): QuantConv2d(\n",
       "      64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): QuantConv2d(\n",
       "      128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): QuantConv2d(\n",
       "      128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): QuantConv2d(\n",
       "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): QuantConv2d(\n",
       "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): QuantConv2d(\n",
       "      256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): QuantConv2d(\n",
       "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): QuantConv2d(\n",
       "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (32): ReLU(inplace=True)\n",
       "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (34): QuantConv2d(\n",
       "      512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "    (35): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (36): ReLU(inplace=True)\n",
       "    (37): QuantConv2d(\n",
       "      8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "    (38): ReLU(inplace=True)\n",
       "    (39): QuantConv2d(\n",
       "      8, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (weight_quant): weight_quantize_fn()\n",
       "    )\n",
       "    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (41): ReLU(inplace=True)\n",
       "    (42): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (43): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
       "  )\n",
       "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "091cb55b-e1ef-4072-8e2f-1cc7d1cfd51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 9157/10000 (92%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "model.eval()\n",
    "model.cuda()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "182a4ce2-e274-4128-8818-8b49a5186506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned QuantConv2d layer: features.0\n",
      "Pruned QuantConv2d layer: features.3\n",
      "Pruned QuantConv2d layer: features.7\n",
      "Pruned QuantConv2d layer: features.10\n",
      "Pruned QuantConv2d layer: features.14\n",
      "Pruned QuantConv2d layer: features.17\n",
      "Pruned QuantConv2d layer: features.20\n",
      "Pruned QuantConv2d layer: features.24\n",
      "Pruned QuantConv2d layer: features.27\n",
      "Pruned QuantConv2d layer: features.30\n",
      "Pruned QuantConv2d layer: features.34\n",
      "Pruned QuantConv2d layer: features.37\n",
      "Pruned QuantConv2d layer: features.39\n"
     ]
    }
   ],
   "source": [
    "#### Prune all the QuantConv2D layers' 80% weights with structured pruning.\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, QuantConv2d):  # Check if the layer is a QuantConv2d layerprune.ln_structured(layer, name='weight', amount=0.8, dim=0, n=1)  # Apply pruning\n",
    "        \n",
    "        prune.ln_structured(layer, name='weight', amount=0.8, dim=0, n=1)  # Apply pruning    #n=1, use L1 norm, n=2, use L2 norm\n",
    "        # prune.ln_structured(layer, name='weight', amount=0.5, dim=0, n=1)\n",
    "        # prune.ln_structured(layer, name='weight', amount=0.3, dim=0, n=1)\n",
    "        \n",
    "        print(f\"Pruned QuantConv2d layer: {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b313d1-117f-4b2f-9b0d-23b2de1d1f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unstructured Pruning executed here, use either one here, dont use both pruning methods\n",
    "\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "for name, layer in model.named_modules():\n",
    "    if isinstance(layer, QuantConv2d):  # Check if the layer is a QuantConv2d layerprune.ln_structured(layer, name='weight', amount=0.8, dim=0, n=1)  # Apply pruning\n",
    "       \n",
    "        # prune.l1_unstructured(layer, name='weight', amount=0.8)\n",
    "        # prune.l1_unstructured(layer, name='weight', amount=0.5)\n",
    "        # prune.l1_unstructured(layer, name='weight', amount=0.3)\n",
    "        \n",
    "        print(f\"Pruned QuantConv2d layer: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48abdb3e-0cde-40af-bc2d-7fb8674d53c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity level:  tensor(0.8008, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "### Check sparsity ###\n",
    "mask = model.features[30].weight_mask\n",
    "sparsity_mask = (mask == 0).sum() / mask.nelement()\n",
    "\n",
    "# weight = model.features[30].weight\n",
    "# sparsity_mask = (weight == 0).sum() / weight.nelement()\n",
    "\n",
    "print(\"Sparsity level: \", sparsity_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc67f3c1-258f-409e-9519-afe79db21775",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check accuracy after pruning, but before finetuning \n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f27aa13a-54fd-4e79-b7e4-22100a1e7b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 2.140607\n",
      "Epoch: 2 \tTraining Loss: 1.688480\n",
      "Epoch: 3 \tTraining Loss: 1.371289\n",
      "Epoch: 4 \tTraining Loss: 1.154713\n",
      "Epoch: 5 \tTraining Loss: 1.023836\n",
      "Epoch: 6 \tTraining Loss: 0.947824\n",
      "Epoch: 7 \tTraining Loss: 0.891423\n",
      "Epoch: 8 \tTraining Loss: 0.857185\n",
      "Epoch: 9 \tTraining Loss: 0.837516\n",
      "Epoch: 10 \tTraining Loss: 0.810638\n",
      "Epoch: 11 \tTraining Loss: 0.790641\n",
      "Epoch: 12 \tTraining Loss: 0.772068\n",
      "Epoch: 13 \tTraining Loss: 0.755202\n",
      "Epoch: 14 \tTraining Loss: 0.745211\n",
      "Epoch: 15 \tTraining Loss: 0.728888\n",
      "Epoch: 16 \tTraining Loss: 0.726871\n",
      "Epoch: 17 \tTraining Loss: 0.715367\n",
      "Epoch: 18 \tTraining Loss: 0.706288\n",
      "Epoch: 19 \tTraining Loss: 0.703068\n",
      "Epoch: 20 \tTraining Loss: 0.690103\n",
      "Epoch: 21 \tTraining Loss: 0.685171\n",
      "Epoch: 22 \tTraining Loss: 0.685071\n",
      "Epoch: 23 \tTraining Loss: 0.680264\n",
      "Epoch: 24 \tTraining Loss: 0.677284\n",
      "Epoch: 25 \tTraining Loss: 0.675615\n",
      "Epoch: 26 \tTraining Loss: 0.667237\n",
      "Epoch: 27 \tTraining Loss: 0.665243\n",
      "Epoch: 28 \tTraining Loss: 0.662890\n",
      "Epoch: 29 \tTraining Loss: 0.659615\n",
      "Epoch: 30 \tTraining Loss: 0.658680\n",
      "Epoch: 31 \tTraining Loss: 0.657170\n",
      "Epoch: 32 \tTraining Loss: 0.650721\n",
      "Epoch: 33 \tTraining Loss: 0.650826\n",
      "Epoch: 34 \tTraining Loss: 0.640990\n",
      "Epoch: 35 \tTraining Loss: 0.645460\n",
      "Epoch: 36 \tTraining Loss: 0.642285\n",
      "Epoch: 37 \tTraining Loss: 0.639081\n",
      "Epoch: 38 \tTraining Loss: 0.637310\n",
      "Epoch: 39 \tTraining Loss: 0.637713\n",
      "Epoch: 40 \tTraining Loss: 0.634266\n",
      "Epoch: 41 \tTraining Loss: 0.635055\n",
      "Epoch: 42 \tTraining Loss: 0.631183\n",
      "Epoch: 43 \tTraining Loss: 0.628494\n",
      "Epoch: 44 \tTraining Loss: 0.632980\n",
      "Epoch: 45 \tTraining Loss: 0.626530\n",
      "Epoch: 46 \tTraining Loss: 0.623216\n",
      "Epoch: 47 \tTraining Loss: 0.625264\n",
      "Epoch: 48 \tTraining Loss: 0.629606\n",
      "Epoch: 49 \tTraining Loss: 0.620860\n",
      "Epoch: 50 \tTraining Loss: 0.622587\n"
     ]
    }
   ],
   "source": [
    "# 1. Version of Training, does not save the checkpoint\n",
    "\n",
    "model.cuda()\n",
    "n_epochs = 50\n",
    "lr = 0.05\n",
    "weight_decay = 1e-4\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "# per epoch, all the training data set is used once\n",
    "model.train() # prep model for training\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for data, target in trainloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*data.size(0) # as loss is tensor, .item() needed to get the value\n",
    "        \n",
    "    # print training statistics, calculate average loss over an epoch\n",
    "    train_loss = train_loss/len(trainloader.dataset)\n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch+1, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5e24752b-4904-4c67-91d1-c614e319a80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Accuracy: 8231/10000 (82.31%)\n"
     ]
    }
   ],
   "source": [
    "## check your accuracy again after finetuning\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f573a1c-bb7b-4b4d-92f0-73f7edc4a71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 -th layer prehooked\n",
      "7 -th layer prehooked\n",
      "12 -th layer prehooked\n",
      "16 -th layer prehooked\n",
      "21 -th layer prehooked\n",
      "25 -th layer prehooked\n",
      "29 -th layer prehooked\n",
      "34 -th layer prehooked\n",
      "38 -th layer prehooked\n",
      "42 -th layer prehooked\n",
      "47 -th layer prehooked\n",
      "51 -th layer prehooked\n",
      "54 -th layer prehooked\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    def __call__(self, module, module_in):\n",
    "        self.outputs.append(module_in)  # Save the input tensor\n",
    "    def clear(self):\n",
    "        self.outputs = []  \n",
    "\n",
    "save_output = SaveOutput()\n",
    "device = torch.device(\"cuda\" if use_gpu else \"cpu\") \n",
    "i = 0\n",
    "count=0\n",
    "\n",
    "for layer in model.modules():\n",
    "    i = i+1\n",
    "    if isinstance(layer, QuantConv2d):\n",
    "        print(i,\"-th layer prehooked\")\n",
    "        layer.register_forward_pre_hook(save_output)    \n",
    "        count = count +1\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.cuda()\n",
    "out = model(images)\n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10cebe62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 8, 2, 2]), torch.Size([256, 8, 2, 2]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_input = save_output.outputs[11][0]\n",
    "layer_output = save_output.outputs[12][0]\n",
    "layer_input.size(), layer_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07b70db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 2, 2]), torch.Size([8, 2, 2]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_input = layer_input[0]\n",
    "layer_output = layer_output[0]\n",
    "layer_input.size(), layer_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7737adeb-d8a4-45e6-a435-1b67394fafa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantConv2d(\n",
      "  8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ")\n",
      "odict_keys(['bias', 'act_alpha', 'weight_q', 'weight_orig'])\n",
      "OrderedDict([('wgt_alpha', Parameter containing:\n",
      "tensor(0.4924, device='cuda:0', requires_grad=True))])\n"
     ]
    }
   ],
   "source": [
    "# grab data from the 37th layer!!!\n",
    "\n",
    "layer = model.features[37]\n",
    "print(layer)\n",
    "\n",
    "print(layer._parameters.keys())\n",
    "\n",
    "print(layer.weight_quant._parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96b409b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 8, 3, 3])\n",
      "tensor([[[[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 7.0000,  7.0000,  7.0000],\n",
      "          [-7.0000, -3.0000,  3.0000],\n",
      "          [-7.0000, -5.0000, -6.0000]],\n",
      "\n",
      "         [[ 7.0000,  7.0000,  7.0000],\n",
      "          [-7.0000,  7.0000,  7.0000],\n",
      "          [ 7.0000, -7.0000,  7.0000]],\n",
      "\n",
      "         [[-7.0000,  7.0000,  6.0000],\n",
      "          [-7.0000,  6.0000, -7.0000],\n",
      "          [ 7.0000, -7.0000, -7.0000]],\n",
      "\n",
      "         [[ 7.0000, -7.0000,  7.0000],\n",
      "          [ 7.0000,  7.0000,  7.0000],\n",
      "          [-7.0000, -7.0000, -7.0000]],\n",
      "\n",
      "         [[-7.0000,  7.0000, -7.0000],\n",
      "          [ 7.0000,  7.0000, -7.0000],\n",
      "          [ 7.0000,  7.0000,  7.0000]],\n",
      "\n",
      "         [[ 7.0000, -7.0000, -7.0000],\n",
      "          [ 7.0000, -7.0000, -7.0000],\n",
      "          [ 7.0000,  7.0000, -7.0000]],\n",
      "\n",
      "         [[ 7.0000,  7.0000,  7.0000],\n",
      "          [ 7.0000, -7.0000, -7.0000],\n",
      "          [-7.0000, -7.0000, -7.0000]],\n",
      "\n",
      "         [[-7.0000,  7.0000, -7.0000],\n",
      "          [-3.0000,  7.0000, -7.0000],\n",
      "          [-7.0000,  1.0000,  7.0000]]],\n",
      "\n",
      "\n",
      "        [[[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 7.0000,  7.0000,  7.0000],\n",
      "          [ 7.0000,  7.0000,  1.0000],\n",
      "          [-6.0000,  7.0000,  7.0000]],\n",
      "\n",
      "         [[ 7.0000,  7.0000,  7.0000],\n",
      "          [ 7.0000, -7.0000, -7.0000],\n",
      "          [-7.0000, -7.0000,  7.0000]],\n",
      "\n",
      "         [[ 6.0000,  7.0000,  7.0000],\n",
      "          [-7.0000,  7.0000, -7.0000],\n",
      "          [-7.0000,  7.0000,  7.0000]],\n",
      "\n",
      "         [[-7.0000, -7.0000,  4.0000],\n",
      "          [-2.0000, -7.0000,  7.0000],\n",
      "          [ 7.0000,  7.0000,  7.0000]],\n",
      "\n",
      "         [[ 7.0000,  7.0000, -7.0000],\n",
      "          [-7.0000, -7.0000,  7.0000],\n",
      "          [-7.0000,  7.0000,  7.0000]],\n",
      "\n",
      "         [[ 7.0000,  7.0000,  7.0000],\n",
      "          [-7.0000,  7.0000,  7.0000],\n",
      "          [ 7.0000, -7.0000, -7.0000]],\n",
      "\n",
      "         [[ 7.0000,  7.0000, -7.0000],\n",
      "          [ 7.0000,  7.0000,  7.0000],\n",
      "          [-7.0000,  7.0000,  7.0000]],\n",
      "\n",
      "         [[ 7.0000,  7.0000, -7.0000],\n",
      "          [-0.0000, -2.0000,  7.0000],\n",
      "          [ 7.0000, -5.0000, -2.0000]]],\n",
      "\n",
      "\n",
      "        [[[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]]],\n",
      "\n",
      "\n",
      "        [[[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]]],\n",
      "\n",
      "\n",
      "        [[[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]]],\n",
      "\n",
      "\n",
      "        [[[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]],\n",
      "\n",
      "         [[-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000],\n",
      "          [-2.0000, -2.0000, -2.0000]]]], device='cuda:0',\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "bw = 4\n",
    "weight_q = layer.weight_q\n",
    "w_alpha = layer.weight_quant.wgt_alpha\n",
    "w_delta = w_alpha / (2**(bw-1)-1)\n",
    "w_int = weight_q / w_delta\n",
    "\n",
    "print(w_int.shape)\n",
    "print(w_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4cff92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 2, 2])\n",
      "tensor([[[ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 3.0000, 13.0000],\n",
      "         [ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000]],\n",
      "\n",
      "        [[ 4.0000,  4.0000],\n",
      "         [ 4.0000,  4.0000]],\n",
      "\n",
      "        [[ 1.0000,  1.0000],\n",
      "         [ 1.0000,  1.0000]],\n",
      "\n",
      "        [[15.0000,  0.0000],\n",
      "         [ 4.0000,  2.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000]]], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = layer_input\n",
    "x_alpha = model.features[37].act_alpha\n",
    "x_delta = x_alpha / (2**(bw)-1)\n",
    "\n",
    "act_quant_fn = act_quantization(bw)\n",
    "x_q = act_quant_fn(x, x_alpha)\n",
    "\n",
    "x_int = x_q / x_delta\n",
    "\n",
    "print(x_int.shape)\n",
    "print(x_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19731e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 2, 2])\n",
      "torch.Size([8, 2, 2])\n",
      "tensor([[[  0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000]],\n",
      "\n",
      "        [[  7.0000, 259.0000],\n",
      "         [147.0000, 287.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000]],\n",
      "\n",
      "        [[ 91.0000,   0.0000],\n",
      "         [286.9999, 273.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000]],\n",
      "\n",
      "        [[  0.0000,   0.0000],\n",
      "         [  0.0000,   0.0000]]], device='cuda:0', grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "conv_int = torch.nn.Conv2d(in_channels=8, out_channels=8, kernel_size=3, padding=1, bias=False)\n",
    "conv_int.weight = torch.nn.parameter.Parameter(w_int)\n",
    "output_int = F.relu(conv_int(x_int))\n",
    "output_recovered = output_int * w_delta * x_delta  # recover with x_delta and w_delta\n",
    "\n",
    "print(output_recovered.shape) \n",
    "print(layer_output.shape)\n",
    "print(output_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91fb5d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7229e-07, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# calculate the difference between outputs, d should be less than 1e-03\n",
    "diff = abs(layer_output - output_recovered)\n",
    "print(diff.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d72fa20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(x_int.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30f02437-dae7-4c86-8b22-f6f4bfc2bdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16])\n"
     ]
    }
   ],
   "source": [
    "x_pad = torch.zeros(8, 4, 4).cuda()\n",
    "\n",
    "x_pad[:, 1:3, 1:3] = x_int.cuda()\n",
    "\n",
    "X = torch.reshape(x_pad, (x_pad.size(0), -1))\n",
    "\n",
    "print(X.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54c08cc9-730d-4c95-a7ce-e625a4461939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "# Define the folder path\n",
    "folder_path = Path('./prun_vgg_output/')\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "folder_path.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b517be83-b9e8-41de-bd4a-a4dc9a23756a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### store weights ###\n",
    "\n",
    "bit_precision = 4\n",
    "file = open('./prun_vgg_output/activation.txt', 'w') \n",
    "file.write('#time0row7[msb-lsb],time0row6[msb-lst],....,time0row0[msb-lst]#\\n')\n",
    "file.write('#time1row7[msb-lsb],time1row6[msb-lst],....,time1row0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for i in range(X.size(1)):  # time step\n",
    "    for j in range(X.size(0)): # row #\n",
    "        X_bin = '{0:04b}'.format(round(X[7-j,i].item()))\n",
    "        for k in range(bit_precision):\n",
    "            file.write(X_bin[k])        \n",
    "        #file.write(' ')  # use this line for visibility with blank between words\n",
    "    file.write('\\n')\n",
    "file.close() #close file    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "637aa7a7-1b29-44a1-af37-81b625cd7edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 8, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8, 9])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(w_int.size())\n",
    "W = torch.reshape(w_int, (w_int.size(0), w_int.size(1), -1))\n",
    "W.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12e6ea1d-b1cb-41bf-918b-b7cb19263af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### storing weight data ###                     \n",
    "\n",
    "bit_precision = 4\n",
    "\n",
    "file = open('./prun_vgg_output/weight.txt', 'w') \n",
    "file.write('#col0row7[msb-lsb],col0row6[msb-lsb],....,col0row0[msb-lsb]#\\n')\n",
    "file.write('#col1row7[msb-lsb],col1row6[msb-lsb],....,col1row0[msb-lsb]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for kij in range(9):\n",
    "    for i in range(W.size(0)):   #col\n",
    "        for j in range(W.size(1)):    # row  \n",
    "            if (W[i, 7-j, kij].item()<0):\n",
    "                W_bin = '{0:04b}'.format(round(W[i,7-j, kij].item() + 2**bit_precision))        #check again if it works for neg numbers\n",
    "            else:\n",
    "                W_bin = '{0:04b}'.format(round(W[i,7-j, kij].item()))\n",
    "            for k in range(bit_precision):\n",
    "                file.write(W_bin[k])        \n",
    "                #file.write(' ')  # for visibility with blank between words, you can use\n",
    "        file.write('\\n')\n",
    "file.close() #close file  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "956ecd4f-17ee-4afc-b879-26fc8f7fc472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 2, 2])\n",
      "torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "print(output_int.size())\n",
    "O = torch.reshape(output_int, (output_int.size(0), -1))\n",
    "print(O.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ffd5ae36-5f08-4672-9d60-08a504b47543",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Store output data ###\n",
    "\n",
    "bit_precision = 16\n",
    "file = open('./prun_vgg_output/output.txt', 'w') #write to file\n",
    "file.write('#time0col7[msb-lsb],time0col6[msb-lsb],....,time0col0[msb-lsb]#\\n')\n",
    "file.write('#time1col7[msb-lsb],time1col6[msb-lsb],....,time1col0[msb-lsb]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for i in range(O.size(1)):  \n",
    "    for j in range(O.size(0)): \n",
    "        if (O[7-j,i].item()<0):\n",
    "            O_bin = '{0:016b}'.format(round(O[7-j,i].item() + 2**bit_precision))\n",
    "        else:\n",
    "            O_bin = '{0:016b}'.format(round(O[7-j,i].item()))\n",
    "        for k in range(bit_precision):\n",
    "            file.write(O_bin[k])        \n",
    "        #file.write(' ')  # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close() #close file    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6f85b68-fc7c-4ac1-9508-a3c968679857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16])\n"
     ]
    }
   ],
   "source": [
    "print(X.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a7172c5a-0f83-4399-97e4-1afeed5fabb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16, 9])\n"
     ]
    }
   ],
   "source": [
    "psum = torch.zeros(8, 16, 9).cuda()  #initialize an empty psum first with array size, p_nij and kij\n",
    "print(psum.size())\n",
    "\n",
    "# calculate psum value\n",
    "for kij in range(9):    \n",
    "    for p_nij in range(16):     \n",
    "        m = nn.Linear(8, 8, bias=False)  # array size matched\n",
    "        m.weight = torch.nn.Parameter(W[:,:,kij])\n",
    "        psum[:, p_nij, kij] = m(X[:,p_nij]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e561a8c2-043f-46e8-bb9f-b80ede973578",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Store psum data ###\n",
    "\n",
    "bit_precision = 16\n",
    "\n",
    "file = open('./prun_vgg_output/psum.txt', 'w') #write to file\n",
    "file.write('#time0col7[msb-lsb],time0col6[msb-lsb],....,time0col0[msb-lsb]#\\n')\n",
    "file.write('#time1col7[msb-lsb],time1col6[msb-lsb],....,time1col0[msb-lsb]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for kij in range(9):\n",
    "    for i in range(psum.size(1)):  # time step\n",
    "        for j in range(psum.size(0)): # array size\n",
    "            if (psum[7-j,i, kij].item()<0):\n",
    "                psum_bin = '{0:016b}'.format(round(psum[7-j,i, kij].item() + 2**bit_precision))\n",
    "            else:\n",
    "                psum_bin = '{0:016b}'.format(round(psum[7-j,i, kij].item()))\n",
    "            for k in range(bit_precision):\n",
    "                file.write(psum_bin[k])        \n",
    "            #file.write(' ')  # for visibility with blank between words, you can use\n",
    "        file.write('\\n')\n",
    "file.close() #close file    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0ea8a5-85de-4619-a401-9977b652d15a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85884b8f-e7ee-407d-b06d-4a965ad6a78f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c4b360-59c8-44c8-9496-52b1f66fa4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
